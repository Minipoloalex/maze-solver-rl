behaviors:
  MazeBBT:
    trainer_type: ppo               # SAC also works; PPO is default & stable
    hyperparameters:
      learning_rate: 3e-4
      batch_size: 1024
      buffer_size: 20480
      beta: 5e-4
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
    network_settings:
      hidden_units: 128
      num_layers: 2
      memory:
        sequence_length: 64         # gives the agent short-term memory
        memory_size: 256
      normalize: true
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    max_steps: 10e6                 # ~2-4 h on a modern GPU with 16 envs
    time_horizon: 128

environment_parameters:
  maze_seed:
    sampler_type: uniform
    sampler_parameters: {min_value: 0, max_value: 2_000_000}

  difficulty:               # later used for curriculum
    sampler_type: uniform
    sampler_parameters: {min_value: 0.1, max_value: 1.0}

  ball_mass:
    sampler_type: gaussian
    sampler_parameters: {mean: 1.0, st_dev: 0.2}
